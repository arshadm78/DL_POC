{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings, os, pickle, math, pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from vis.utils import utils\n",
    "from vis.input_modifiers import Jitter\n",
    "\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import image\n",
    "from keras.models import load_model\n",
    "from keras import backend as K, activations\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptionv3_preprocessor_input\n",
    "from keras.applications.inception_v3 import decode_predictions as inceptionv3_decode_predictions\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocessor_input\n",
    "from keras.applications.vgg16 import decode_predictions as vgg16_decode_predictions\n",
    "\n",
    "from keras.applications import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocessor_input\n",
    "from keras.applications.vgg19 import decode_predictions as vgg19_decode_predictions\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as resnet50_preprocessor_input\n",
    "from keras.applications.resnet50 import decode_predictions as resnet50_decode_predictions\n",
    "\n",
    "\n",
    "\n",
    "global model\n",
    "global modelvgg16\n",
    "global modelvgg19\n",
    "global modelinceptionv3\n",
    "global modelresnet50\n",
    "global input_width\n",
    "global input_height\n",
    "global decode_predictions\n",
    "global preprocess_input\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "model = None\n",
    "modelvgg16 = None\n",
    "modelvgg19 = None\n",
    "modelinceptionv3 = None\n",
    "modelresnet50 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switchvgg16():\n",
    "    global model\n",
    "    global modelvgg16\n",
    "    global input_width\n",
    "    global input_height\n",
    "    global decode_predictions\n",
    "    global preprocess_input\n",
    "    \n",
    "    input_width = 224\n",
    "    input_height = 224\n",
    "    model = modelvgg16\n",
    "    preprocess_input = vgg16_preprocessor_input\n",
    "    decode_predictions = vgg16_decode_predictions\n",
    "     \n",
    "def switchvgg19():\n",
    "    global model\n",
    "    global modelvgg19\n",
    "    global input_width\n",
    "    global input_height\n",
    "    input_width = 224\n",
    "    input_height = 224\n",
    "    model = modelvgg19\n",
    "    preprocess_input = vgg19_preprocessor_input\n",
    "    decode_predictions = vgg19_decode_predictions\n",
    "     \n",
    "    \n",
    "def switchinceptionv3():\n",
    "    global model\n",
    "    global modelinceptionv3\n",
    "    global input_width\n",
    "    global input_height\n",
    "    global decode_predictions\n",
    "    global preprocess_input\n",
    "    \n",
    "    input_width = 299\n",
    "    input_height = 299\n",
    "    model = modelinceptionv3\n",
    "    preprocess_input = inceptionv3_preprocessor_input\n",
    "    decode_predictions = inceptionv3_decode_predictions\n",
    "    \n",
    "    \n",
    "def switchresnet50():\n",
    "    global model\n",
    "    global modelresnet50\n",
    "    global input_width\n",
    "    global input_height\n",
    "    global decode_predictions\n",
    "    global preprocess_input\n",
    "    \n",
    "    input_width = 224\n",
    "    input_height = 224\n",
    "    model = modelresnet50\n",
    "    preprocess_input = resnet50_preprocessor_input\n",
    "    decode_predictions = resnet50_decode_predictions\n",
    "    \n",
    "    \n",
    "def loadinceptionv3():\n",
    "    global modelinceptionv3\n",
    "    \n",
    "    print \"Loading Inception ... \"\n",
    "    if modelinceptionv3 is None:\n",
    "        modelinceptionv3 = InceptionV3(weights='imagenet')\n",
    "    print \"Model loaded\"\n",
    "   \n",
    "    switchinceptionv3()\n",
    "    \n",
    "def loadresnet50():\n",
    "    global modelresnet50\n",
    "    \n",
    "    print \"Loading Resnet50 ... \"\n",
    "    if modelresnet50 is None:\n",
    "        modelresnet50 = ResNet50(weights='imagenet')\n",
    "    print \"Model loaded\"\n",
    "    \n",
    "    switchresnet50()\n",
    "    \n",
    "def loadvgg16():\n",
    "    global modelvgg16\n",
    "\n",
    "    print \"Loading VGG16 ... \"\n",
    "    if modelvgg16 is None:\n",
    "        modelvgg16 =  VGG16(weights='imagenet')\n",
    "    print \"Model loaded\"\n",
    "    switchvgg16()\n",
    "\n",
    "def loadvgg19():\n",
    "    global modelvgg19\n",
    "    \n",
    "    print \"Loading VGG19 ... \"\n",
    "    if modelvgg19 is None:\n",
    "        modelvgg19 =  VGG19(weights='imagenet')\n",
    "    print \"Model loaded\"\n",
    "    switchvgg19()\n",
    "    \n",
    "    \n",
    "def doinference(path):\n",
    "    global model\n",
    "    img_path = path\n",
    "    img = image.load_img(img_path, target_size=(input_width, input_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:',  decode_predictions(preds))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "def vgg():\n",
    "    vgg = VGG16(weights='imagenet', include_top=False);\n",
    "    layer_outputs = [layer.output for layer in vgg.layers if 'conv1' in layer.name]\n",
    "    for layer in vgg.layers:\n",
    "        print layer.name\n",
    "    \n",
    "    activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
    "    intermediate_activations = activation_model.predict(img_tensor)\n",
    "    first_layer_activation = intermediate_activations[0]\n",
    "#plt.imshow(first_layer_activation[0, :, :, 19], cmap='viridis')\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "    for layerll in intermediate_activations:\n",
    "        showlayer(layerll)\n",
    "\n",
    "    \n",
    "def vggpredict():\n",
    "    model = VGG16(weights='imagenet')\n",
    "    #model = keras.models.load_model(\"/home/arshad/.keras/models/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "    img_path = '/home/arshad/projects/Paper/zebra.jpg'\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', decode_predictions(preds))\n",
    "\n",
    "def inception():\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    #model = keras.models.load_model(\"/home/arshad/.keras/models/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "    img_path = '/home/arshad/projects/Paper/zebra.jpg'\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', decode_predictions(preds))\n",
    "    \n",
    "def showlayer(layeroutput):\n",
    "    w=10\n",
    "    h=10\n",
    "    \n",
    "    w = layeroutput.shape[1]\n",
    "    h = layeroutput.shape[2]\n",
    "    count =  layeroutput.shape[3]\n",
    "    print count\n",
    "    fig=plt.figure(figsize=(w, h))\n",
    "    columns = int( math.sqrt(count))\n",
    "    rows = int(math.sqrt(count)) \n",
    "    print columns , rows\n",
    "    for i in range(1, columns*rows +1 ):\n",
    "        #img = np.random.randint(10, size=(h,w))\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(layeroutput[0,:,:, i-1], cmap='gray')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    \n",
    "img_path = '/home/arshad/projects/Paper/horse.jpg'\n",
    "\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "print(img_tensor.shape)\n",
    "#plt.imshow(img_tensor[0])\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VGG16 ... \n",
      "WARNING:tensorflow:From /home/arshad/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model loaded\n",
      "('Predicted:', [[(u'n02391049', u'zebra', 0.99975437), (u'n02423022', u'gazelle', 8.930854e-05), (u'n02422699', u'impala', 7.757987e-05), (u'n02422106', u'hartebeest', 6.339619e-05), (u'n01518878', u'ostrich', 7.049558e-06)]])\n",
      "Loading VGG19 ... \n",
      "Model loaded\n",
      "('Predicted:', [[(u'n02391049', u'zebra', 0.9999635), (u'n02422106', u'hartebeest', 1.5399242e-05), (u'n02423022', u'gazelle', 1.4861966e-05), (u'n02422699', u'impala', 4.251905e-06), (u'n02397096', u'warthog', 1.2643867e-06)]])\n",
      "Loading Inception ... \n",
      "Model loaded\n",
      "('Predicted:', [[(u'n02391049', u'zebra', 0.9497816), (u'n02422106', u'hartebeest', 0.001496049), (u'n01518878', u'ostrich', 0.0007340291), (u'n02422699', u'impala', 0.00049439847), (u'n02437312', u'Arabian_camel', 0.00039523802)]])\n",
      "Loading Resnet50 ... \n",
      "Model loaded\n",
      "('Predicted:', [[(u'n02391049', u'zebra', 0.99970645), (u'n02422106', u'hartebeest', 7.984984e-05), (u'n02423022', u'gazelle', 5.0528175e-05), (u'n02129604', u'tiger', 4.6689584e-05), (u'n02422699', u'impala', 4.387298e-05)]])\n"
     ]
    }
   ],
   "source": [
    "file='/home/arshad/projects/Paper/zebra.jpg'\n",
    "loadvgg16()\n",
    "doinference(file)\n",
    "loadvgg19()\n",
    "doinference(file)\n",
    "loadinceptionv3()\n",
    "doinference(file)\n",
    "loadresnet50()\n",
    "doinference(file)\n",
    "#pdb.set_trace() #drop to python shell\n",
    "#plt.style.use('ggplot')\n",
    "#plt.imshow(img_tensor[0])\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "    \n",
    "#print \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
